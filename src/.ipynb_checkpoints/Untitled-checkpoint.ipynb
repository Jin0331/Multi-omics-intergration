{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "import umap.umap_ as umap\n",
    "\n",
    "# keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **UDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cancer_select(DF, cancer_type):\n",
    "    # phenotype\n",
    "    phe1 = pd.read_csv(\"https://gdc-hub.s3.us-east-1.amazonaws.com/download/GDC-PANCAN.basic_phenotype.tsv.gz\", sep=\"\\t\")\n",
    "    phe1 = phe1.loc[phe1.program == \"TCGA\", :].loc[:, ['sample', 'sample_type', 'project_id']].drop_duplicates(['sample'])\n",
    "    phe1['sample'] =  phe1.apply(lambda x : x['sample'][:-1], axis=1)\n",
    "    phe2 = pd.read_csv(\"https://tcga-pancan-atlas-hub.s3.us-east-1.amazonaws.com/download/TCGA_phenotype_denseDataOnlyDownload.tsv.gz\", sep=\"\\t\")\n",
    "    ph_join = pd.merge(left = phe2 , right = phe1, how = \"left\", on = \"sample\").dropna(subset=['project_id'])\n",
    "    \n",
    "    if cancer_type == \"PAN\" or cancer_type == \"PANCAN\":\n",
    "        filterd = ph_join.loc[ph_join['sample_type_y'] == \"Primary Tumor\", :]\n",
    "        sample_barcode = filterd[\"sample\"].tolist()\n",
    "    else:\n",
    "        filterd = ph_join.loc[(ph_join['sample_type_y'] == \"Primary Tumor\") & (ph_join['project_id'] == \"TCGA-\" + cancer_type) , :]\n",
    "        sample_barcode = filterd[\"sample\"].tolist()\n",
    "        \n",
    "    intersect_ = list(set(DF.columns.tolist()).intersection(sample_barcode))\n",
    "    \n",
    "    return intersect_\n",
    "\n",
    "def non_zero_column(DF):\n",
    "    sample_cnt = int(len(DF.columns) * 0.2)\n",
    "    zero_row = dict(DF.isin([0]).sum(axis=1))\n",
    "    non_remove_feature = list()\n",
    "\n",
    "    for key, value in zero_row.items():\n",
    "        if value < sample_cnt:\n",
    "            non_remove_feature.append(key)\n",
    "    \n",
    "    return non_remove_feature\n",
    "\n",
    "\n",
    "def determine_outlier_thresholds_iqr(dataframe, col_name, th1=0.05, th3=0.95):\n",
    "    quartile1 = dataframe[col_name].quantile(th1)\n",
    "    quartile3 = dataframe[col_name].quantile(th3)\n",
    "    iqr = quartile3 - quartile1\n",
    "    upper_limit = quartile3 + 1.5 * iqr\n",
    "    lower_limit = quartile1 - 1.5 * iqr\n",
    "    return lower_limit, upper_limit\n",
    "\n",
    "def check_outliers_iqr(dataframe, col_name):\n",
    "    lower_limit, upper_limit = determine_outlier_thresholds_iqr(dataframe, col_name)\n",
    "    if dataframe[(dataframe[col_name] > upper_limit) | (dataframe[col_name] < lower_limit)].any(axis=None):\n",
    "        return True\n",
    "    else: \n",
    "        return False\n",
    "    \n",
    "def replace_with_thresholds_iqr(dataframe, cols, th1=0.05, th3=0.95, replace=False):\n",
    "    from tabulate import tabulate\n",
    "    data = []\n",
    "    for col_name in cols:\n",
    "        if col_name != 'Outcome':\n",
    "            outliers_ = check_outliers_iqr(dataframe,col_name)\n",
    "            count = None\n",
    "            lower_limit, upper_limit = determine_outlier_thresholds_iqr(dataframe, col_name, th1, th3)\n",
    "            if outliers_:\n",
    "                count = dataframe[(dataframe[col_name] > upper_limit) | (dataframe[col_name] < lower_limit)][col_name].count()\n",
    "                if replace: \n",
    "                    dataframe.loc[(dataframe[col_name] < lower_limit), col_name] = lower_limit\n",
    "                    dataframe.loc[(dataframe[col_name] > upper_limit), col_name] = upper_limit\n",
    "            outliers_status = check_outliers_iqr(dataframe, col_name)\n",
    "            data.append([outliers_, outliers_status, count, col_name, lower_limit, upper_limit ])\n",
    "    table = tabulate(data, headers=['Outliers (Previously)', 'Outliers', 'Count', 'Column', 'Lower Limit', 'Upper Limit'], tablefmt='rst', numalign='right')\n",
    "   \n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def get_dataset(path, cancer_type, std):\n",
    "    # non_scale dataset\n",
    "    # load raw DF\n",
    "    DF = pd.read_csv(path + \"/feature/input_feature_non_scale/\" + cancer_type + \".txt\", sep = \"\\t\")\n",
    "    pr_sample_DF = DF.iloc[:, 0:1]\n",
    "\n",
    "    if cancer_type == \"PANCAN\":\n",
    "        DF = DF.drop([\"Sample_barcode\"], axis=1)\n",
    "    else :\n",
    "        DF = DF.drop([\"Project\", \"Sample_barcode\"], axis=1)\n",
    "        \n",
    "    # remove outlier\n",
    "    DF = replace_with_thresholds_iqr(dataframe=DF, cols=DF.columns)\n",
    "    max_number_of_nas = DF.shape[0] / 2\n",
    "    DF = DF.loc[:, (DF.isnull().sum(axis=0) <= max_number_of_nas)]\n",
    "\n",
    "    # normalization\n",
    "    if std:\n",
    "        scalerX = StandardScaler()\n",
    "        scalerX.fit(DF)\n",
    "        DF_sacle = scalerX.transform(DF)\n",
    "    else :\n",
    "        scalerX = MinMaxScaler()\n",
    "        scalerX.fit(X_train)\n",
    "        DF_sacle = scalerX.transform(DF)\n",
    "    \n",
    "    # missing impute\n",
    "    imputer = KNNImputer(n_neighbors=10)\n",
    "    DF_sacle_impute = imputer.fit_transform(DF_sacle)\n",
    "\n",
    "    DF_sacle_impute = pd.DataFrame(DF_sacle_impute, columns=DF.columns)\n",
    "\n",
    "    return DF_sacle_impute\n",
    "\n",
    "# z = z_mean + sqrt(var) * epsilon\n",
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
    "    # Arguments\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "    # Returns\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean = 0 and std = 1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def get_train_test_DF(x, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, shuffle=True, random_state=32, stratify=y)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def createFolder(path):\n",
    "    try:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "    except OSError:\n",
    "        print ('Folder already exists. ' +  path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **File Path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_file_path = \"/home/wmbio/WORK/multi-omics/HCC_integration/RAW_DATA/\"\n",
    "MODEL_path = \"/home/jovyan/work/models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **RNA gene expression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna = pd.read_csv(RAW_file_path + \"tcga_RSEM_Hugo_norm_count.gz\", sep = \"\\t\", index_col=0)\n",
    "rna = rna[cancer_select(DF=rna,cancer_type=\"LIHC\")]\n",
    "rna = rna[rna.index.isin(non_zero_column(rna))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **miRNA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Methylation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = pd.read_csv(RAW_file_path + \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiomic_37",
   "language": "python",
   "name": "multiomics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
